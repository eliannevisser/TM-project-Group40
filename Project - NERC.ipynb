{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f5e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b21d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_train = ['ignore','words','pos','chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2083c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ConllCorpusReader(r\"/Users/twanpostma/AI/TextMining/FINALASSIGNMENT\", ['output.tsv'], columns_train, separator='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d49cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_list_train = []\n",
    "ne_labels_list_train = []\n",
    "counter = 0\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    counter+=1\n",
    "    if counter == (450001):\n",
    "        break\n",
    "    a_dict = {\n",
    "       'words' : token,\n",
    "        'pos' : pos\n",
    "    }\n",
    "    dictionary_list_train.append(a_dict)\n",
    "    ne_labels_list_train.append(ne_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8201e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tag', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe']\n"
     ]
    }
   ],
   "source": [
    "# print(len(dictionary_list_train))\n",
    "dictionary_list_train_part = dictionary_list_train[:450000]\n",
    "print(ne_labels_list_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbb0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import nltk\n",
    "\n",
    "# test_df = pd.read_csv(\"NER-final-test.tsv\", delimiter='\\t')\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e828e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pos_tag(sentence):\n",
    "#     tokens = nltk.word_tokenize(sentence)\n",
    "#     tags = [tag for _, tag in nltk.pos_tag(tokens)]\n",
    "#     return ' '.join(tags)\n",
    "\n",
    "# test_df['pos'] = test_df['token'].apply(pos_tag)\n",
    "\n",
    "# test_df = test_df.drop(columns=['sentence id', 'token id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3adf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #specify path for export\n",
    "# path = r'C:\\Users\\Elianne\\Documents\\VU AI 22-23\\Text Mining\\ba-text-mining\\lab_sessions\\text-data-processed.txt'\n",
    "\n",
    "# #export DataFrame to text file\n",
    "# with open(path, 'a') as f:\n",
    "#     df_string = test_df.to_string(header=True, index=False)\n",
    "#     f.write(df_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3ebdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ConllCorpusReader(r\"/Users/twanpostma/AI/TextMining/FINALASSIGNMENT\",\n",
    "                          'NERC_FINALFINALTEST.txt',\n",
    "                          ['words', 'pos', 'chunk'], separator='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b616a88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'words': 'It', 'pos': 'PRP\\r'}, {'words': 'took', 'pos': 'VBD\\r'}, {'words': 'eight', 'pos': 'CD\\r'}, {'words': 'years', 'pos': 'NNS\\r'}, {'words': 'for', 'pos': 'IN\\r'}, {'words': 'Warner', 'pos': 'NNP\\r'}, {'words': 'Brothers', 'pos': 'NNS\\r'}, {'words': 'to', 'pos': 'TO\\r'}, {'words': 'recover', 'pos': 'NN\\r'}, {'words': 'from', 'pos': 'IN\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'disaster', 'pos': 'NN\\r'}, {'words': 'that', 'pos': 'IN\\r'}, {'words': 'was', 'pos': 'VBD\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'movie', 'pos': 'NN\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'All', 'pos': 'DT\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'New', 'pos': 'NNP\\r'}, {'words': 'York', 'pos': 'NNP\\r'}, {'words': 'University', 'pos': 'NNP\\r'}, {'words': 'students', 'pos': 'NNS\\r'}, {'words': 'love', 'pos': 'NN\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'diner', 'pos': 'NN\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'Soho', 'pos': 'NN\\r'}, {'words': 'so', 'pos': 'RB\\r'}, {'words': 'it', 'pos': 'PRP\\r'}, {'words': 'makes', 'pos': 'VBZ\\r'}, {'words': 'for', 'pos': 'IN\\r'}, {'words': 'a', 'pos': 'DT\\r'}, {'words': 'fun', 'pos': 'NN\\r'}, {'words': 'young', 'pos': 'JJ\\r'}, {'words': 'atmosphere', 'pos': 'RB\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'This', 'pos': 'DT\\r'}, {'words': 'Italian', 'pos': 'JJ\\r'}, {'words': 'place', 'pos': 'NN\\r'}, {'words': 'is', 'pos': 'VBZ\\r'}, {'words': 'really', 'pos': 'RB\\r'}, {'words': 'trendy', 'pos': 'NN\\r'}, {'words': 'but', 'pos': 'CC\\r'}, {'words': 'they', 'pos': 'PRP\\r'}, {'words': 'have', 'pos': 'VB\\r'}, {'words': 'forgotten', 'pos': 'NNS\\r'}, {'words': 'about', 'pos': 'IN\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'most', 'pos': 'JJS\\r'}, {'words': 'important', 'pos': 'JJ\\r'}, {'words': 'part', 'pos': 'NN\\r'}, {'words': 'of', 'pos': 'IN\\r'}, {'words': 'a', 'pos': 'DT\\r'}, {'words': 'restaurant', 'pos': 'NN\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'food', 'pos': 'NN\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'In', 'pos': 'IN\\r'}, {'words': 'conclusion', 'pos': 'NN\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'my', 'pos': 'PRP\\r'}, {'words': 'review', 'pos': 'NN\\r'}, {'words': 'of', 'pos': 'IN\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'book', 'pos': 'NN\\r'}, {'words': 'would', 'pos': 'MD\\r'}, {'words': 'be', 'pos': 'VB\\r'}, {'words': ':', 'pos': ':\\r'}, {'words': 'I', 'pos': 'PRP\\r'}, {'words': 'like', 'pos': 'IN\\r'}, {'words': 'Jane', 'pos': 'NN\\r'}, {'words': 'Austen', 'pos': 'VB\\r'}, {'words': 'and', 'pos': 'CC\\r'}, {'words': 'understand', 'pos': 'NN\\r'}, {'words': 'why', 'pos': 'WRB\\r'}, {'words': 'she', 'pos': 'PRP\\r'}, {'words': 'is', 'pos': 'VBZ\\r'}, {'words': 'famous', 'pos': 'JJ\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'The', 'pos': 'DT\\r'}, {'words': 'story', 'pos': 'NN\\r'}, {'words': 'of', 'pos': 'IN\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'movie', 'pos': 'NN\\r'}, {'words': 'is', 'pos': 'VBZ\\r'}, {'words': 'focused', 'pos': 'VBN\\r'}, {'words': 'on', 'pos': 'IN\\r'}, {'words': 'Carl', 'pos': 'NNP\\r'}, {'words': 'Brashear', 'pos': 'IN\\r'}, {'words': 'played', 'pos': 'NNS\\r'}, {'words': 'by', 'pos': 'IN\\r'}, {'words': 'Cuba', 'pos': 'NNP\\r'}, {'words': 'Gooding', 'pos': 'VBG\\r'}, {'words': 'Jr.', 'pos': 'NNP\\r'}, {'words': 'who', 'pos': 'WP\\r'}, {'words': 'wants', 'pos': 'VBZ\\r'}, {'words': 'to', 'pos': 'TO\\r'}, {'words': 'be', 'pos': 'VB\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'first', 'pos': 'RB\\r'}, {'words': 'African', 'pos': ']JJ\\r'}, {'words': 'American', 'pos': 'JJ\\r'}, {'words': 'deep', 'pos': 'NN\\r'}, {'words': 'sea', 'pos': 'NN\\r'}, {'words': 'diver', 'pos': 'NN\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'Navy', 'pos': 'NNP\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'Chris', 'pos': 'NN\\r'}, {'words': \"O'Donnell\", 'pos': 'NN\\r'}, {'words': 'stated', 'pos': 'VBN\\r'}, {'words': 'that', 'pos': 'IN\\r'}, {'words': 'while', 'pos': 'IN\\r'}, {'words': 'filming', 'pos': 'VBG\\r'}, {'words': 'for', 'pos': 'IN\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'movie', 'pos': 'NN\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'he', 'pos': 'PRP\\r'}, {'words': 'felt', 'pos': 'NN\\r'}, {'words': 'like', 'pos': 'IN\\r'}, {'words': 'he', 'pos': 'PRP\\r'}, {'words': 'was', 'pos': 'VBD\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'a', 'pos': 'DT\\r'}, {'words': 'toy', 'pos': 'NN\\r'}, {'words': 'commercial', 'pos': 'JJ\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'My', 'pos': 'PRP\\r'}, {'words': 'husband', 'pos': 'NN\\r'}, {'words': 'and', 'pos': 'CC\\r'}, {'words': 'I', 'pos': 'PRP\\r'}, {'words': 'moved', 'pos': 'VBN\\r'}, {'words': 'to', 'pos': 'TO\\r'}, {'words': 'Amsterdam', 'pos': 'NN\\r'}, {'words': '6', 'pos': 'CD\\r'}, {'words': 'years', 'pos': 'NNS\\r'}, {'words': 'ago', 'pos': 'RB\\r'}, {'words': 'and', 'pos': 'CC\\r'}, {'words': 'for', 'pos': 'IN\\r'}, {'words': 'as', 'pos': 'IN\\r'}, {'words': 'long', 'pos': 'RB\\r'}, {'words': 'as', 'pos': 'IN\\r'}, {'words': 'we', 'pos': 'PRP\\r'}, {'words': 'have', 'pos': 'VB\\r'}, {'words': 'lived', 'pos': 'VBD\\r'}, {'words': 'here', 'pos': 'RB\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'Blauwbrug', 'pos': 'NN\\r'}, {'words': 'has', 'pos': 'VBZ\\r'}, {'words': 'been', 'pos': 'VBN\\r'}, {'words': 'our', 'pos': 'PRP\\r'}, {'words': 'favorite', 'pos': 'NN\\r'}, {'words': 'place', 'pos': 'NN\\r'}, {'words': 'to', 'pos': 'TO\\r'}, {'words': 'eat', 'pos': 'NN\\r'}, {'words': '!', 'pos': '.\\r'}, {'words': 'Dame', 'pos': 'NN\\r'}, {'words': 'Maggie', 'pos': 'NNP\\r'}, {'words': 'Smith', 'pos': 'NNP\\r'}, {'words': 'performed', 'pos': 'VBN\\r'}, {'words': 'her', 'pos': 'PRP\\r'}, {'words': 'role', 'pos': 'NN\\r'}, {'words': 'excellently', 'pos': 'RB\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'as', 'pos': 'IN\\r'}, {'words': 'she', 'pos': 'PRP\\r'}, {'words': 'does', 'pos': 'VBZ\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'all', 'pos': 'DT\\r'}, {'words': 'her', 'pos': 'PRP\\r'}, {'words': 'movies', 'pos': 'NNS\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'The', 'pos': 'DT\\r'}, {'words': 'new', 'pos': 'JJ\\r'}, {'words': 'movie', 'pos': 'NN\\r'}, {'words': 'by', 'pos': 'IN\\r'}, {'words': 'Mr.', 'pos': 'NNP\\r'}, {'words': 'Kruno', 'pos': 'NNP\\r'}, {'words': 'was', 'pos': 'VBD\\r'}, {'words': 'shot', 'pos': 'NN\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'New', 'pos': 'NNP\\r'}, {'words': 'York', 'pos': 'NNP\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'but', 'pos': 'CC\\r'}, {'words': 'the', 'pos': 'DT\\r'}, {'words': 'story', 'pos': 'NN\\r'}, {'words': 'takes', 'pos': 'VBZ\\r'}, {'words': 'place', 'pos': 'NN\\r'}, {'words': 'in', 'pos': 'IN\\r'}, {'words': 'Los', 'pos': 'NNP\\r'}, {'words': 'Angeles', 'pos': 'NNP\\r'}, {'words': '.', 'pos': '.\\r'}, {'words': 'I', 'pos': 'PRP\\r'}, {'words': 'always', 'pos': 'RB\\r'}, {'words': 'have', 'pos': 'VB\\r'}, {'words': 'loved', 'pos': 'VBN\\r'}, {'words': 'English', 'pos': 'JJ\\r'}, {'words': 'novels', 'pos': 'NNS\\r'}, {'words': ',', 'pos': ',\\r'}, {'words': 'but', 'pos': 'CC\\r'}, {'words': 'I', 'pos': 'PRP\\r'}, {'words': 'just', 'pos': 'RB\\r'}, {'words': 'could', 'pos': 'MD\\r'}, {'words': \"n't\", 'pos': 'RB\\r'}, {'words': 'get', 'pos': 'VB\\r'}, {'words': 'into', 'pos': 'IN\\r'}, {'words': 'this', 'pos': 'DT\\r'}, {'words': 'one', 'pos': 'CD\\r'}, {'words': '.', 'pos': '.'}]\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "dictionary_list_test = []\n",
    "ne_labels_list_test = []\n",
    "\n",
    "for token, ne_label, pos in test.iob_words():\n",
    "    a_dict = {\n",
    "       'words' : token,\n",
    "        'pos' : pos\n",
    "    }\n",
    "    dictionary_list_test.append(a_dict)\n",
    "    ne_labels_list_test.append(ne_label)\n",
    "\n",
    "ne_labels_list_test = [i.strip() for i in ne_labels_list_test] \n",
    "dictionary_list_test = dictionary_list_test[1:]\n",
    "ne_labels_list_test = ne_labels_list_test[1:]\n",
    "print(dictionary_list_test)\n",
    "print(ne_labels_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15cf1d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450000 1048568 450000\n",
      "214 215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer()\n",
    "the_array = dictionary_list_train_part + dictionary_list_test\n",
    "vectorized = vec.fit_transform(the_array).toarray()\n",
    "train_vectorized = vectorized[:450000]\n",
    "test_vectorized = vectorized[450000:]\n",
    "\n",
    "print(len(train_vectorized), len(train.iob_words()), len(ne_labels_list_train))\n",
    "print(len(test_vectorized), len(test.iob_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4619856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d331cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f39a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.fit(train_vectorized, ne_labels_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "758c38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lin_clf.predict(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851d7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         4\n",
      "      B-MISC       0.00      0.00      0.00         3\n",
      "       B-ORG       0.00      0.00      0.00         4\n",
      "       B-PER       0.00      0.00      0.00         6\n",
      "       B-gpe       0.00      0.00      0.00         0\n",
      "       I-LOC       0.00      0.00      0.00         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.00      0.00      0.00         3\n",
      "       I-PER       0.00      0.00      0.00         8\n",
      "           O       0.87      1.00      0.93       183\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.09      0.10      0.09       214\n",
      "weighted avg       0.75      0.86      0.80       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/twanpostma/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ne_labels_list_test, classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdaf42a-dce6-4226-89a0-0cdb739f941f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
